{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd031f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Image classification training on a DEBIAI project with a dataset generator\n",
    "\n",
    "This tutorial shows how to classify images of flowers after inserting the project contextual into DEBIAI.\n",
    "\n",
    "Based on the tensorflow tutorial : https://www.tensorflow.org/tutorials/images/classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import TensorFlow and other libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# The pythonModule folder need to be in the same folder \n",
    "from debiai import debiai"
   ]
  },
  {
   "source": [
    "## Download and explore the dataset\n",
    "\n",
    "This tutorial uses a dataset of about 3,700 photos of flowers. The dataset contains 5 sub-directories, one per class:\n",
    "\n",
    "daisy, dandelion, roses, sunflowers and tulips\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "dataset_url = \"https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz\"\n",
    "data_dir = tf.keras.utils.get_file('flower_photos', origin=dataset_url, untar=True)\n",
    "data_dir = pathlib.Path(data_dir)\n"
   ]
  },
  {
   "source": [
    "## Create a dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some parameters for the loader:\n",
    "\n",
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 3670 files belonging to 5 classes.\nUsing 2936 files for training.\n"
     ]
    }
   ],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"training\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 3670 files belonging to 5 classes.\nUsing 734 files for validation.\n"
     ]
    }
   ],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir,\n",
    "  validation_split=0.2,\n",
    "  subset=\"validation\",\n",
    "  seed=123,\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['daisy', 'dandelion', 'roses', 'sunflowers', 'tulips']\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "source": [
    "## Insert the project contextual data in DEBIAI"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of the DEBIAI project block structure\n",
    "DEBIAI_block_structure = [\n",
    "    {\n",
    "        \"name\": \"image_id\",\n",
    "        \"groundTruth\": [\n",
    "            { \"name\": \"class\",           \"type\": \"text\"},\n",
    "        ],\n",
    "        \"contexts\": [\n",
    "            { \"name\": \"img_path\",        \"type\": \"text\"},\n",
    "        ]\n",
    "    }\n",
    "]"
   ]
  },
  {
   "source": [
    "#### Converting some of the project data in a dataframe\n",
    "\n",
    "In this exemple, it is done with the creation of a dataframe\n",
    "\n",
    "more details here : \n",
    "https://git.irt-systemx.fr/ML/DEBIAI/pythonModule#adding-samples"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      image_id   class                                           img_path\n",
       "0            0   daisy  /home/tomansion/.keras/datasets/flower_photos/...\n",
       "1            1   daisy  /home/tomansion/.keras/datasets/flower_photos/...\n",
       "2            2   daisy  /home/tomansion/.keras/datasets/flower_photos/...\n",
       "3            3   daisy  /home/tomansion/.keras/datasets/flower_photos/...\n",
       "4            4   daisy  /home/tomansion/.keras/datasets/flower_photos/...\n",
       "...        ...     ...                                                ...\n",
       "3665      3665  tulips  /home/tomansion/.keras/datasets/flower_photos/...\n",
       "3666      3666  tulips  /home/tomansion/.keras/datasets/flower_photos/...\n",
       "3667      3667  tulips  /home/tomansion/.keras/datasets/flower_photos/...\n",
       "3668      3668  tulips  /home/tomansion/.keras/datasets/flower_photos/...\n",
       "3669      3669  tulips  /home/tomansion/.keras/datasets/flower_photos/...\n",
       "\n",
       "[3670 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_id</th>\n      <th>class</th>\n      <th>img_path</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>daisy</td>\n      <td>/home/tomansion/.keras/datasets/flower_photos/...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>daisy</td>\n      <td>/home/tomansion/.keras/datasets/flower_photos/...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>daisy</td>\n      <td>/home/tomansion/.keras/datasets/flower_photos/...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>daisy</td>\n      <td>/home/tomansion/.keras/datasets/flower_photos/...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>daisy</td>\n      <td>/home/tomansion/.keras/datasets/flower_photos/...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3665</th>\n      <td>3665</td>\n      <td>tulips</td>\n      <td>/home/tomansion/.keras/datasets/flower_photos/...</td>\n    </tr>\n    <tr>\n      <th>3666</th>\n      <td>3666</td>\n      <td>tulips</td>\n      <td>/home/tomansion/.keras/datasets/flower_photos/...</td>\n    </tr>\n    <tr>\n      <th>3667</th>\n      <td>3667</td>\n      <td>tulips</td>\n      <td>/home/tomansion/.keras/datasets/flower_photos/...</td>\n    </tr>\n    <tr>\n      <th>3668</th>\n      <td>3668</td>\n      <td>tulips</td>\n      <td>/home/tomansion/.keras/datasets/flower_photos/...</td>\n    </tr>\n    <tr>\n      <th>3669</th>\n      <td>3669</td>\n      <td>tulips</td>\n      <td>/home/tomansion/.keras/datasets/flower_photos/...</td>\n    </tr>\n  </tbody>\n</table>\n<p>3670 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "source": [
    "# Creation of a dataframe with the same columns as the block structure\n",
    "data = {\"image_id\": [], \"class\": [], \"img_path\": []}\n",
    "i = 0\n",
    "for class_name in class_names:\n",
    "    images = list(data_dir.glob(class_name + '/*'))\n",
    "\n",
    "    for image in images:\n",
    "        data[\"image_id\"].append(i)\n",
    "        data[\"class\"].append(class_name)\n",
    "        data[\"img_path\"].append(str(image))\n",
    "        i += 1\n",
    "\n",
    "df = pd.DataFrame(data=data)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creation of a DEBIAI instance\n",
    "DEBIAI_BACKEND_URL = 'http://localhost:3000/'\n",
    "DEBIAI_PROJECT_NAME = 'Image classification demo'\n",
    "my_debiai = debiai.Debiai(DEBIAI_BACKEND_URL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "DEBIAI project : 'Image classification demo'"
      ]
     },
     "metadata": {},
     "execution_count": 37
    }
   ],
   "source": [
    "# Creation of a DEBIAI project if it doesn't exist\n",
    "debiai_project = my_debiai.get_project(DEBIAI_PROJECT_NAME)\n",
    "\n",
    "if not debiai_project :\n",
    "    debiai_project = my_debiai.create_project(DEBIAI_PROJECT_NAME)\n",
    "\n",
    "debiai_project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "[{'contexts': [{'name': 'img_path', 'type': 'text'}],\n",
       "  'groundTruth': [{'name': 'class', 'type': 'text'}],\n",
       "  'name': 'image_id'}]"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "source": [
    "# Set the project block_structure if not already done\n",
    "if not debiai_project.block_structure_defined():\n",
    "    debiai_project.set_blockstructure(DEBIAI_block_structure)\n",
    "debiai_project.get_block_structure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 39
    }
   ],
   "source": [
    "# Adding the dataframe\n",
    "debiai_project.add_samples_pd(df, get_hash=False)"
   ]
  },
  {
   "source": [
    "## Create the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(class_names)\n",
    "\n",
    "model = Sequential([\n",
    "  layers.experimental.preprocessing.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(num_classes)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nrescaling (Rescaling)        (None, 180, 180, 3)       0         \n_________________________________________________________________\nconv2d (Conv2D)              (None, 180, 180, 16)      448       \n_________________________________________________________________\nmax_pooling2d (MaxPooling2D) (None, 90, 90, 16)        0         \n_________________________________________________________________\nconv2d_1 (Conv2D)            (None, 90, 90, 32)        4640      \n_________________________________________________________________\nmax_pooling2d_1 (MaxPooling2 (None, 45, 45, 32)        0         \n_________________________________________________________________\nconv2d_2 (Conv2D)            (None, 45, 45, 64)        18496     \n_________________________________________________________________\nmax_pooling2d_2 (MaxPooling2 (None, 22, 22, 64)        0         \n_________________________________________________________________\nflatten (Flatten)            (None, 30976)             0         \n_________________________________________________________________\ndense (Dense)                (None, 128)               3965056   \n_________________________________________________________________\ndense_1 (Dense)              (None, 5)                 645       \n=================================================================\nTotal params: 3,989,285\nTrainable params: 3,989,285\nNon-trainable params: 0\n_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "source": [
    "## Train the model with the DEBIAI Dataset generator"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Because DEBIAI doesn't have the images to train the models, we will provide them with a function that take a sample information based on the given block_structure\n",
    "\n",
    "def model_input_from_debiai_sample(debiai_sample: dict):\n",
    "    # \"image_id\", \"class\", \"img_path\"\n",
    "    img = keras.preprocessing.image.load_img(\n",
    "        debiai_sample['img_path'], target_size=(img_height, img_width))\n",
    "    img_array = keras.preprocessing.image.img_to_array(img)\n",
    "    return tf.expand_dims(img_array, 0)  # Create a batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF generated dataset \n",
    "train_dataset_imported = debiai_project.get_tf_dataset_with_provided_inputs(\n",
    "    model_input_from_debiai_sample,\n",
    "    output_types=(tf.float32, tf.int32),\n",
    "    output_shapes=([None, img_height, img_width, 3], [1, ]),\n",
    "    classes=class_names\n",
    ")\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_dataset_imported = train_dataset_imported.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "# get_tf_dataset_with_provided_inputs Also work with a selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/3\n",
      "3670/3670 [==============================] - 229s 57ms/step - loss: 1.0292 - accuracy: 0.5483\n",
      "Epoch 2/3\n",
      "3670/3670 [==============================] - 147s 40ms/step - loss: 0.9190 - accuracy: 0.5619\n",
      "Epoch 3/3\n",
      "3670/3670 [==============================] - 147s 40ms/step - loss: 0.7756 - accuracy: 0.6721\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7febfc637a30>"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "# Train the model\n",
    "epochs = 3\n",
    "model.fit(train_dataset_imported, epochs=epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}