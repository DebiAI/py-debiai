{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEBIAI Python module tutorial\n",
    "\n",
    "## 0. Introduction\n",
    "\n",
    "#### This tutorial has been designed to show you how to use the DEBIAI python module to import data from your models into the app.\n",
    "#### From the dataset creation to the result display in DEBIAI, you can follow this tutorial with the same dataset as ours or just use your own instead."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System modules\n",
    "import importlib\n",
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Tensorflow modules\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "# Math modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import random\n",
    "import pandas as pd\n",
    "import scipy\n",
    "\n",
    "# Image modules\n",
    "import PIL\n",
    "import PIL.Image\n",
    "\n",
    "# DEBIAI module\n",
    "# While not upload in pip, use this, with package in parent directory\n",
    "sys.path.insert(1, os.path.join(sys.path[0], '..'))\n",
    "from debiai import debiai"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Datasets creations\n",
    "\n",
    "#### First, we are going to load and reformat datasets to be used in this tutorial. You can skip this section if you already have some data to play with.\n",
    "##### _See Tutorial_data.ipynb_ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Models and results functions\n",
    "\n",
    "#### Here are some functions that will be helpful during the example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models creation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_from_dir(path, batch_size=32, nb_layers=3):\n",
    "    \"\"\" \n",
    "    Create a CNN model from directories of images grouped by labels.\n",
    "    Return the train and val dataset and the model.\n",
    "    \"\"\"\n",
    "    data_dir = pathlib.Path(path)\n",
    "    \n",
    "    # Create a dataset\n",
    "    img_height = 32\n",
    "    img_width = 32\n",
    "\n",
    "    train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=0.2,\n",
    "        subset='training',\n",
    "        seed=123,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size)\n",
    "\n",
    "    val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        data_dir,\n",
    "        validation_split=0.2,\n",
    "        subset='validation',\n",
    "        seed=123,\n",
    "        image_size=(img_height, img_width),\n",
    "        batch_size=batch_size)\n",
    "    \n",
    "    model = create_cnn_model(batch_size=batch_size, nb_layers=nb_layers)\n",
    "    \n",
    "    return (train_ds, val_ds, model)\n",
    " \n",
    "def create_cnn_model(batch_size=32, nb_layers=3):\n",
    "    \"\"\" Return a CNN model for 32*32*3 inputs images \n",
    "        nb_layers allow to choose number of Conv2D, MaxPooling2D layers\n",
    "    \"\"\"\n",
    "    # Create model\n",
    "    num_classes = 10\n",
    "    \n",
    "    l = []\n",
    "    \n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    \n",
    "    model.add(layers.experimental.preprocessing.Rescaling(1./255))\n",
    "    \n",
    "    for i in range(nb_layers):\n",
    "        model.add(layers.Conv2D(32, 3, activation='relu'))\n",
    "        model.add(layers.MaxPooling2D())\n",
    "        \n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dense(num_classes))\n",
    "\n",
    "    # Compile model functions\n",
    "    model.compile(\n",
    "      optimizer='adam',\n",
    "      loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      metrics=['accuracy'])\n",
    "\n",
    "    model.build((batch_size,32,32,3))\n",
    "    model.summary()\n",
    "    \n",
    "    return model\n",
    "\n",
    "def visualize_dataset(dataset):\n",
    "    \"\"\" Display a set of 9 images from the dataset \"\"\"\n",
    "    # Visualize data\n",
    "    plt.figure(figsize=(10,10))\n",
    "    class_name = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "    for images, labels in dataset.take(1):\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "            plt.title(class_name[labels[i]])\n",
    "            plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_samples_from_dataset(iterator, nb_batch):\n",
    "    \"\"\" Get a samples of inputs from the dataset (in nb of batch)\"\"\"\n",
    "    l = []\n",
    "    \n",
    "    for i in iterator:\n",
    "        if nb_batch == 0:\n",
    "            break\n",
    "        nb_batch -= 1\n",
    "        \n",
    "        for j in range(32):\n",
    "            row = []\n",
    "        \n",
    "            row.append(i[0][j])\n",
    "            row.append(i[1][j])\n",
    "        \n",
    "            l.append(row)\n",
    "        \n",
    "    return np.asarray(l)\n",
    "\n",
    "from scipy.special import softmax\n",
    "\n",
    "def predict_input(sample, model):\n",
    "    \"\"\" Predict one input - used in predict_from_pd()\"\"\"\n",
    "    reshape_sample = sample.reshape(1,32,32,3)\n",
    "                \n",
    "    # Add predictions to result\n",
    "    pred = model.predict(reshape_sample, batch_size = 1)\n",
    "    \n",
    "    sft = softmax(pred)\n",
    "    percent = (str(round(np.max(sft) * 100, 2)))\n",
    "    return (str(np.argmax(pred)), percent)\n",
    "\n",
    "def predict_from_pd(df, model):\n",
    "    \"\"\" Predict result from a dataframe of inputs \"\"\"\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df[\"hash\"] = df[\"hash\"]\n",
    "    new_df[\"results\"]= df.apply(lambda x: predict_input(x['inputs'], model), axis=1)\n",
    "    new_df[['results', 'percents']] = pd.DataFrame(new_df['results'].tolist(), index=df.index)\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Debiai modular project\n",
    "\n",
    "#### We acknowledge that the datasets are already created before starting this section\n",
    "\n",
    "#### To start with, let's introduce the context to our example: \n",
    "* We need to create a basic AI capable of recognizing digits. To do so we start by training one model with the MNIST dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 70000 files belonging to 10 classes.\n",
      "Using 56000 files for training.\n",
      "Found 70000 files belonging to 10 classes.\n",
      "Using 14000 files for validation.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling (Rescaling)        (32, 32, 32, 3)           0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (32, 30, 30, 32)          896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (32, 15, 15, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (32, 7200)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (32, 128)                 921728    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (32, 10)                  1290      \n",
      "=================================================================\n",
      "Total params: 923,914\n",
      "Trainable params: 923,914\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We get the mnist dataset, validation set and model from this function\n",
    "(mnist_ds, mnist_val, mnist_model_1) = create_model_from_dir(\"data/MNIST_reformat/\", nb_layers=1)\n",
    "\n",
    "# We get the iterator for later use\n",
    "mnist_iter = mnist_val.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to take 100 batch of 32 samples for our first visualization.\n",
    "mnist_val_data = get_samples_from_dataset(mnist_iter, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a dataframe for the samples\n",
    "columns = [\"inputs\",\"GT\"]\n",
    "data_mnist = pd.DataFrame(mnist_val_data, columns=columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have data, we can add them to debiai by creating a new project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's create a debiai project\n",
    "importlib.reload(debiai)\n",
    "\n",
    "# We need to precise where is running our debiai backend (by default it's this one)\n",
    "my_debiai = debiai.Debiai(\"http://localhost:3000/\")\n",
    "\n",
    "# Just by safety, we delete any project that could be named as our's and create a new one.\n",
    "project = my_debiai.delete_project_byId(\"Digit-Recognition\")\n",
    "project = my_debiai.create_project(\"Digit-Recognition\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In debiai, data are stored following the blockstructure of the project, this one has to be specified before any import of data into it. The blockstructure works like a tree with first block being the roots (contexts) and last being the leaves (samples). \n",
    "#### Here we just have regular samples without context, so we can just put one block representing the leaves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we create a block structure to design the architecture of the DEBIAI project\n",
    "# We only have the GroundTruth label for now but let's put it for the example\n",
    "\n",
    "first_block_struct = [{\n",
    "        \n",
    "        # Block Samples\n",
    "        \"name\":\"image\",\n",
    "        \"groundTruth\": [\n",
    "            {\n",
    "                \"name\":\"GT\",\n",
    "                \"type\":\"number\"\n",
    "            }\n",
    "        ],\n",
    "        \"contexts\": [],\n",
    "        \"others\": [],\n",
    "        \"inputs\" : [],\n",
    "    }\n",
    "]\n",
    "\n",
    "project.set_blockstructure(first_block_struct)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To add samples into a project, every blocks name and attributes of it must be present in the dataframe. Moreover, to see every samples separately, we need to give a unique block name for the last block (sample) as his ID.\n",
    "\n",
    "#### In our example that means that each row of sample should have a \"image\" name (unique) and a \"GT\" number at least. Here, we can use map_id to map the index of your dataframe to the \"image\" block name required even if the name of file is a better name to pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We want to load our data samples into debiai.\n",
    "# The map_id parameter allow to use data.index as an id for samples instead of specifying an \"image\" column.\n",
    "# If you don't want to use map_id, you dataframe need to have an \"images\" column with unique value (such as files names)\n",
    "\n",
    "project.add_samples_pd(data_mnist, map_id=\"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another mandatory element of every debiai project is the Expected_Result structure. It defines how will be the results of every models. There is only one per project, so for now, every models will have same results type in debiai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'results', 'type': 'number'},\n",
       " {'name': 'pourcents', 'type': 'number'}]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's add our first model !\n",
    "debiai_model_1 = project.create_model(\"Model 1\")\n",
    "\n",
    "# We are going to use results so need an expected_results structure.\n",
    "result_struct = [\n",
    "    {\n",
    "        \"name\":\"results\",\n",
    "        \"type\":\"number\"\n",
    "    },\n",
    "    {\n",
    "        \"name\":\"percents\",\n",
    "        \"type\":\"number\"\n",
    "    }\n",
    "]\n",
    "\n",
    "project.set_expected_results(result_struct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Next, we train our model and add results to a newly created debiai model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 625s 357ms/step - loss: 0.1385 - accuracy: 0.9579 - val_loss: 0.0647 - val_accuracy: 0.9793\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2fe1adbc10>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's train our first model\n",
    "mnist_model_1.fit(mnist_ds, validation_data=mnist_val, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hash</th>\n",
       "      <th>results</th>\n",
       "      <th>pourcents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1ff70ec879acb37790026a019419e2151dc7821d2a62f5...</td>\n",
       "      <td>5</td>\n",
       "      <td>99.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>102d4b5f5e701a1519ea10d0036ad97fc1a7c6c2be51e2...</td>\n",
       "      <td>1</td>\n",
       "      <td>99.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0f0f302e98b22e49eeb144646a5927b142bf3af1d9949a...</td>\n",
       "      <td>4</td>\n",
       "      <td>89.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>cae0f1a5bb0384316b769377b7b1fc8fa97f5315853114...</td>\n",
       "      <td>0</td>\n",
       "      <td>94.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9db1a02677fc56e855484dde31d4dc7a2ca3a34752b0a8...</td>\n",
       "      <td>2</td>\n",
       "      <td>100.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                hash results pourcents\n",
       "0  1ff70ec879acb37790026a019419e2151dc7821d2a62f5...       5     99.62\n",
       "1  102d4b5f5e701a1519ea10d0036ad97fc1a7c6c2be51e2...       1     99.92\n",
       "2  0f0f302e98b22e49eeb144646a5927b142bf3af1d9949a...       4     89.53\n",
       "3  cae0f1a5bb0384316b769377b7b1fc8fa97f5315853114...       0     94.78\n",
       "4  9db1a02677fc56e855484dde31d4dc7a2ca3a34752b0a8...       2     100.0"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We are now going to predict results to put into debiai\n",
    "df_results_1 = predict_from_pd(data_mnist, mnist_model_1)\n",
    "df_results_1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can now add results to our first model into debiai. Results are stored by models.\n",
    "# Again map_id allows to map a specific column to data.index\n",
    "debiai_model_1.add_results_df(df_results_1, map_id=\"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that we have a model and results into our project, we can create another to compare them into debiai."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_1 (Rescaling)      (32, 32, 32, 3)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (32, 30, 30, 32)          896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (32, 15, 15, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (32, 13, 13, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (32, 6, 6, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (32, 4, 4, 32)            9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (32, 2, 2, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (32, 128)                 0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (32, 128)                 16512     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (32, 10)                  1290      \n",
      "=================================================================\n",
      "Total params: 37,194\n",
      "Trainable params: 37,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We want to try another model with more Conv2D layers\n",
    "mnist_model_2 = create_cnn_model(nb_layers=3)\n",
    "\n",
    "# Add a second model to the block\n",
    "debiai_model_2 = project.create_model(\"Model 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1750/1750 [==============================] - 553s 316ms/step - loss: 0.1757 - accuracy: 0.9458 - val_loss: 0.0601 - val_accuracy: 0.9814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2fd0637070>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train this model\n",
    "mnist_model_2.fit(mnist_ds, validation_data=mnist_val, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We can now predict and add new results to this model in debiai. We will use the same sample as the first model to compare\n",
    "df_results_2 = predict_from_pd(data_mnist, mnist_model_2)\n",
    "df_results_2.head()\n",
    "\n",
    "# Add new results\n",
    "debiai_model_2.add_results_df(df_results_2, map_id=\"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### You can now compare the results of our two models on the same samples into Debiai\n",
    "\n",
    "##### Let's add color to our data to be able to recognize digits with different noise and tones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### For now in order to change the blockstructure of a project and add a new \"dataset\" block we need to create a new project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_debiai.delete_project_byId(\"Digit-Recognition2\")\n",
    "full_project = my_debiai.create_project(\"Digit-Recognition2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'results', 'type': 'number'},\n",
       " {'name': 'pourcents', 'type': 'number'}]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We need to set a new more useful blockstructure for our new datasets\n",
    "\n",
    "second_block_struct = [\n",
    "    {\n",
    "        # Dataset Block\n",
    "        \"name\":\"dataset\",\n",
    "        \"contexts\": [\n",
    "            {\n",
    "                \"name\":\"colored\",\n",
    "                \"type\":\"boolean\"\n",
    "            },\n",
    "            {\n",
    "                \"name\":\"noised\",\n",
    "                \"type\":\"boolean\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    {\n",
    "        # Block Samples\n",
    "        \"name\":\"image\",\n",
    "        \"groundTruth\": [\n",
    "            {\n",
    "                \"name\":\"GT\",\n",
    "                \"type\":\"number\"\n",
    "            }\n",
    "        ],\n",
    "        \"contexts\": [],\n",
    "        \"others\": [],\n",
    "        \"inputs\" : [],\n",
    "    }\n",
    "]\n",
    "\n",
    "full_project.set_blockstructure(second_block_struct)\n",
    "\n",
    "# The results stay the same so let's add them too\n",
    "full_project.set_expected_results(result_struct)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Because we added new contexts, we need to add them to the dataframe too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_mnist['dataset'] = 'mnist'\n",
    "data_mnist['colored'] = False\n",
    "data_mnist['noised'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now we can add the MNIST_M dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 67085 files belonging to 10 classes.\n",
      "Using 53668 files for training.\n",
      "Found 67085 files belonging to 10 classes.\n",
      "Using 13417 files for validation.\n",
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_2 (Rescaling)      (32, 32, 32, 3)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (32, 30, 30, 32)          896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (32, 15, 15, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (32, 13, 13, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (32, 6, 6, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (32, 4, 4, 32)            9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (32, 2, 2, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (32, 128)                 0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (32, 128)                 16512     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (32, 10)                  1290      \n",
      "=================================================================\n",
      "Total params: 37,194\n",
      "Trainable params: 37,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We should create dataset and model for MNIST_M \n",
    "(mnistm_ds, mnistm_val, mnistm_model_1) = create_model_from_dir(\"data/MNIST_M/train\", nb_layers=3)\n",
    "\n",
    "# We get the iterator for later use\n",
    "mnistm_iter = mnistm_val.as_numpy_iterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We are going to take 100 batch of 32 samples here again\n",
    "mnistm_val_data = get_samples_from_dataset(mnistm_iter, 100)\n",
    "\n",
    "# Let's create a dataframe for the samples\n",
    "data_mnistm = pd.DataFrame(mnistm_val_data, columns=columns)\n",
    "\n",
    "# Add specific context to this dataset\n",
    "data_mnistm['dataset'] = 'mnistm'\n",
    "data_mnistm['colored'] = True\n",
    "data_mnistm['noised'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We can now see our two datasets ready to be used. Notice that every attribute of the blockstructure is present except \"image\" which is map to dataframe index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>GT</th>\n",
       "      <th>dataset</th>\n",
       "      <th>colored</th>\n",
       "      <th>noised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[55.0, 61.0, 27.0], [57.0, 63.0, 29.0], [58....</td>\n",
       "      <td>3</td>\n",
       "      <td>mnistm</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[204.0, 180.0, 108.0], [203.0, 179.0, 107.0]...</td>\n",
       "      <td>1</td>\n",
       "      <td>mnistm</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[195.0, 115.0, 80.0], [191.0, 111.0, 76.0], ...</td>\n",
       "      <td>2</td>\n",
       "      <td>mnistm</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[127.0, 127.0, 93.0], [102.0, 102.0, 64.0], ...</td>\n",
       "      <td>7</td>\n",
       "      <td>mnistm</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[74.0, 82.0, 41.0], [35.0, 47.0, 1.0], [23.0...</td>\n",
       "      <td>6</td>\n",
       "      <td>mnistm</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs GT dataset  colored  \\\n",
       "0  [[[55.0, 61.0, 27.0], [57.0, 63.0, 29.0], [58....  3  mnistm     True   \n",
       "1  [[[204.0, 180.0, 108.0], [203.0, 179.0, 107.0]...  1  mnistm     True   \n",
       "2  [[[195.0, 115.0, 80.0], [191.0, 111.0, 76.0], ...  2  mnistm     True   \n",
       "3  [[[127.0, 127.0, 93.0], [102.0, 102.0, 64.0], ...  7  mnistm     True   \n",
       "4  [[[74.0, 82.0, 41.0], [35.0, 47.0, 1.0], [23.0...  6  mnistm     True   \n",
       "\n",
       "   noised  \n",
       "0   False  \n",
       "1   False  \n",
       "2   False  \n",
       "3   False  \n",
       "4   False  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mnistm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The hash you can see here is from the path of the precedent project, so it will not work here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>GT</th>\n",
       "      <th>hash</th>\n",
       "      <th>dataset</th>\n",
       "      <th>colored</th>\n",
       "      <th>noised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>5</td>\n",
       "      <td>1ff70ec879acb37790026a019419e2151dc7821d2a62f5...</td>\n",
       "      <td>mnist</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>102d4b5f5e701a1519ea10d0036ad97fc1a7c6c2be51e2...</td>\n",
       "      <td>mnist</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>4</td>\n",
       "      <td>0f0f302e98b22e49eeb144646a5927b142bf3af1d9949a...</td>\n",
       "      <td>mnist</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>cae0f1a5bb0384316b769377b7b1fc8fa97f5315853114...</td>\n",
       "      <td>mnist</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>2</td>\n",
       "      <td>9db1a02677fc56e855484dde31d4dc7a2ca3a34752b0a8...</td>\n",
       "      <td>mnist</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs GT  \\\n",
       "0  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...  5   \n",
       "1  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...  1   \n",
       "2  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...  4   \n",
       "3  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...  0   \n",
       "4  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...  2   \n",
       "\n",
       "                                                hash dataset  colored  noised  \n",
       "0  1ff70ec879acb37790026a019419e2151dc7821d2a62f5...   mnist    False   False  \n",
       "1  102d4b5f5e701a1519ea10d0036ad97fc1a7c6c2be51e2...   mnist    False   False  \n",
       "2  0f0f302e98b22e49eeb144646a5927b142bf3af1d9949a...   mnist    False   False  \n",
       "3  cae0f1a5bb0384316b769377b7b1fc8fa97f5315853114...   mnist    False   False  \n",
       "4  9db1a02677fc56e855484dde31d4dc7a2ca3a34752b0a8...   mnist    False   False  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mnist.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can now push both dataframe to debiai project\n",
    "full_project.add_samples_pd(data_mnist, map_id=\"image\")\n",
    "full_project.add_samples_pd(data_mnistm, map_id=\"image\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that add_samples_pd has been called, a new hash can be seen, linked to the new path with the new blockstructure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>inputs</th>\n",
       "      <th>GT</th>\n",
       "      <th>hash</th>\n",
       "      <th>dataset</th>\n",
       "      <th>colored</th>\n",
       "      <th>noised</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>5</td>\n",
       "      <td>4d5556a51281631e752fb2ee1dbb54a0814e327bd41c6a...</td>\n",
       "      <td>mnist</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>1</td>\n",
       "      <td>c9117565e04307d797ce53292c3f64fc544a4700285be6...</td>\n",
       "      <td>mnist</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>4</td>\n",
       "      <td>6651aa5c08d18026d4cc1c810d0d290de40508b007dc6e...</td>\n",
       "      <td>mnist</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>0</td>\n",
       "      <td>70421938da0287194cdb0a9160a6a2677f92d8a87837b8...</td>\n",
       "      <td>mnist</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...</td>\n",
       "      <td>2</td>\n",
       "      <td>85ead609f2bf88ece418c632f16c58937bb9edcba8126c...</td>\n",
       "      <td>mnist</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              inputs GT  \\\n",
       "0  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...  5   \n",
       "1  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...  1   \n",
       "2  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...  4   \n",
       "3  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...  0   \n",
       "4  [[[0.0, 0.0, 0.0], [0.0, 0.0, 0.0], [0.0, 0.0,...  2   \n",
       "\n",
       "                                                hash dataset  colored  noised  \n",
       "0  4d5556a51281631e752fb2ee1dbb54a0814e327bd41c6a...   mnist    False   False  \n",
       "1  c9117565e04307d797ce53292c3f64fc544a4700285be6...   mnist    False   False  \n",
       "2  6651aa5c08d18026d4cc1c810d0d290de40508b007dc6e...   mnist    False   False  \n",
       "3  70421938da0287194cdb0a9160a6a2677f92d8a87837b8...   mnist    False   False  \n",
       "4  85ead609f2bf88ece418c632f16c58937bb9edcba8126c...   mnist    False   False  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mnist.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now that the samples are nicely imported into debiai, we just have to create a debiai.model for each of our models and import their predictions results.\n",
    "#### This phase is very repetitive because each new results dataframe created needs to have all the attributes of blockstructure to be able to link it with the correct samples. Because of that, we could set it all inside a function instead of writing it multiples times for different models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we can add models using the two dataframe to see results.\n",
    "# Let's start by adding the previous model with new predictions for the new dataset\n",
    "df_res_mnistm1 = predict_from_pd(data_mnistm, mnist_model_1)\n",
    "\n",
    "# We need to add the others columns to specify which samples we are referring to\n",
    "df_res_mnistm1['dataset'] = 'mnistm'\n",
    "df_res_mnistm1['colored'] = True\n",
    "df_res_mnistm1['noised'] = False\n",
    "df_results_1['dataset'] = 'mnist'\n",
    "df_results_1['colored'] = False\n",
    "df_results_1['noised'] = False\n",
    "\n",
    "debiai_model_1 = full_project.create_model(\"Model 1\")\n",
    "\n",
    "# Push the results into debiai\n",
    "debiai_model_1.add_results_df(df_results_1, map_id=\"image\")\n",
    "debiai_model_1.add_results_df(df_res_mnistm1, map_id=\"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also add the second model already created\n",
    "df_res_mnistm2 = predict_from_pd(data_mnistm, mnist_model_2)\n",
    "\n",
    "# We need to add the others columns to specify which samples we are referring to\n",
    "df_res_mnistm2['dataset'] = 'mnistm'\n",
    "df_res_mnistm2['colored'] = True\n",
    "df_res_mnistm2['noised'] = False\n",
    "df_results_2['dataset'] = 'mnist'\n",
    "df_results_2['colored'] = False\n",
    "df_results_2['noised'] = False\n",
    "\n",
    "debiai_model_2 = full_project.create_model(\"Model 2\")\n",
    "\n",
    "# Push the results into debiai\n",
    "debiai_model_2.add_results_df(df_results_2, map_id=\"image\")\n",
    "debiai_model_2.add_results_df(df_res_mnistm2, map_id=\"image\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1678/1678 [==============================] - 661s 394ms/step - loss: 0.5897 - accuracy: 0.8118 - val_loss: 0.2677 - val_accuracy: 0.9177\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2fb871ccd0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can fit the new model from MNISTM\n",
    "mnistm_model_1.fit(mnistm_ds, validation_data=mnistm_val, epochs=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another way to push results is to link them with the hash so that we do not need to enter all columns like dataset, colored, etc\n",
    "#### Here the predict_from_pd() function also add the associated hash from samples when predicting results, we can use this value to push results into our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can add it to debiai like the others\n",
    "df_res_mnistm3 = predict_from_pd(data_mnistm, mnistm_model_1)\n",
    "df_res_mnist3 = predict_from_pd(data_mnist, mnistm_model_1)\n",
    "\n",
    "debiai_model_3 = full_project.create_model(\"Model 3\")\n",
    "\n",
    "# Push the results into debiai\n",
    "debiai_model_3.add_results_df(df_res_mnist3)\n",
    "debiai_model_3.add_results_df(df_res_mnistm3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "rescaling_3 (Rescaling)      (32, 32, 32, 3)           0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (32, 30, 30, 32)          896       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (32, 15, 15, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (32, 13, 13, 32)          9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (32, 6, 6, 32)            0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (32, 4, 4, 32)            9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (32, 2, 2, 32)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (32, 128)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (32, 128)                 16512     \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (32, 10)                  1290      \n",
      "=================================================================\n",
      "Total params: 37,194\n",
      "Trainable params: 37,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "3428/3428 [==============================] - 1238s 361ms/step - loss: 0.2614 - accuracy: 0.9190 - val_loss: 0.1552 - val_accuracy: 0.9526\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f2fe02060d0>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Last we can add a model trained on both dataset\n",
    "# Merge both dataset\n",
    "full_dataset = mnist_ds.concatenate(mnistm_ds)\n",
    "full_dataset.shuffle(1)\n",
    "full_val = mnist_val.concatenate(mnistm_val)\n",
    "\n",
    "full_model = create_cnn_model()\n",
    "\n",
    "full_model.fit(full_dataset,validation_data=full_val,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now we can add it to debiai like the others\n",
    "df_res_mnistm4= predict_from_pd(data_mnistm, full_model)\n",
    "df_res_mnist4 = predict_from_pd(data_mnist, full_model)\n",
    "\n",
    "debiai_model_4 = full_project.create_model(\"Model 4\")\n",
    "\n",
    "# Push the results into debiai\n",
    "debiai_model_4.add_results_df(df_res_mnist4)\n",
    "debiai_model_4.add_results_df(df_res_mnistm4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### If you don't want to use dataFrame to push results, you can also use a dictionary.  \n",
    "#### This can be a dictionary representing the tree of data using _add_results_dict()_ : \n",
    "```{mnist: {sample_id: [results], ...}, mnistm: {sample_id, [results], ...}, ...}```\n",
    "#### or a dictionary representing hash and results directly using _add_results_hash()_:\n",
    "```{hash: [results], ...}```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Last, we have a remove_expected_result function to delete an expected result and erase every result link to that attribute. Use it carefully !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'results', 'type': 'number'}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can also remove an expected result, this will delete all data linked to this result for each models.\n",
    "full_project.remove_expected_result(\"percents\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion\n",
    "\n",
    "#### You have created a debiai project with 4 models to compare and 2 datasets with different contexts.\n",
    "\n",
    "#### As you may have noticed, we didn't use the \"noised\" context, yet, but we put it for the example for now.\n",
    "#### That's all folks ! Hopes you have fun using Debiai !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TODO\n",
    "\n",
    "* Create a hash based architecture to allow user not to worry about id on samples anymore: **DONE**\n",
    "* Create a better way to charge results without having to put all columns specification (using block as python object certainly)\n",
    "* Create a function to add an expected_result with a default value for already inserted data.\n",
    "* Add new dataset with noised samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
